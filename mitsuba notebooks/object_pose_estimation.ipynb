{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object pose estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, we will show how to optimize the pose of an object while correctly accounting for the visibility discontinuities. We are going to optimize several latent variables that control the translation and rotation of the object.\n",
    "\n",
    "In differentiable rendering, we aim to evaluate the derivative of a pixel intensity integral with respect to a scene parameter $\\pi$ as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\partial_\\pi I(\\pi) = \\partial_\\pi \\int_P f(\\textbf{x}, \\pi) ~ d\\textbf{x}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\textbf{x}$ is a light path in the path space $P$.\n",
    "\n",
    "When the function $f(\\cdot)$ is continuous w.r.t. $\\pi$, we can move the derivative into the integral and then apply Monte Carlo integration. Under this assumption, differentiating the rendering process via automatic differentiation, as in the previous tutorials, is correct.\n",
    "\n",
    "However, if $f(\\cdot)$ has discontinuities w.r.t. $\\pi$, direct application of automatic differentiation is not correct anymore, as it omits an integral term given by the [Reynolds transport theorem](https://en.wikipedia.org/wiki/Reynolds_transport_theorem). This needs to be considered when differentiating shape-related parameters (e.g., position), as the discontinuities in the visiblity function (the silhouette of the object) are then dependent on the differentiated parameter.\n",
    "\n",
    "In the last years, several works tried to address this issue (e.g., <cite data-cite=\"Li2018\">Li et al. (2018)</cite>, <cite data-cite=\"Zhang2020\">Zhang et al. (2020)</cite>, <cite data-cite=\"Loubet2019Reparameterizing\">Loubet et al. (2019)</cite>, <cite data-cite=\"Bangaru2020\">Bangaru et al. (2020)</cite>, ...). Mitsuba provides dedicated integrators implementing the *reparameterization*-based approach (<cite data-cite=\"Loubet2019Reparameterizing\">Loubet et al. (2019)</cite>, <cite data-cite=\"Bangaru2020\">Bangaru et al. (2020)</cite>, <cite data-cite=\"Zeltner2021\">Zeltner et al. (2021)</cite>):\n",
    "\n",
    "- [<code>prb_reparam</code>][1]: reparameterized Path Replay Backpropagation (PRB) integrator\n",
    "- [<code>direct_reparam</code>][2]: reparameterized direct illumination integrator\n",
    "\n",
    "\n",
    "In this tutorial, we will optimize the position and rotation of a mesh in order to match a target rendering. To keep things simple, we will use the `direct_reparam` integrator.\n",
    "\n",
    "\n",
    "<div class=\"admonition important alert alert-block alert-success\">\n",
    "\n",
    "ðŸš€ **You will learn how to:**\n",
    "    \n",
    "<ul>\n",
    "  <li>Perform an optimization with discontinuity-aware methods</li>\n",
    "  <li>Optimize latent variables to control the motion of an object</li>\n",
    "</ul>\n",
    "    \n",
    "</div>\n",
    "\n",
    "[1]: https://mitsuba.readthedocs.io/en/latest/src/generated/plugins_integrators.html#reparameterized-path-replay-backpropagation-integrator-prb-reparam\n",
    "[2]: https://mitsuba.readthedocs.io/en/latest/src/generated/plugins_integrators.html#reparameterized-direct-integrator-direct-reparam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As always, let's import `drjit` and `mitsuba` and set a differentiation-aware variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "mi.set_variant('cuda_ad_rgb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `direct_reparam` and scene construction\n",
    "\n",
    "We will rely on the `direct_reparam` integrator for this tutorial to properly handle the visibility discontinuities in our differentiable simulation. In primal rendering, this integrator is identical to the `direct` integrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator = {\n",
    "    'type': 'direct_reparam',\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a simple scene with a bunny placed in front of a gray wall, illuminated by a spherical light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mitsuba.scalar_rgb import Transform4f as T\n",
    "\n",
    "scene = mi.load_dict({\n",
    "    'type': 'scene',\n",
    "    'integrator': integrator,\n",
    "    'sensor':  {\n",
    "        'type': 'perspective',\n",
    "        'to_world': T.look_at(\n",
    "                        origin=(0, 0, 2),\n",
    "                        target=(0, 0, 0),\n",
    "                        up=(0, 1, 0)\n",
    "                    ),\n",
    "        'fov': 60,\n",
    "        'film': {\n",
    "            'type': 'hdrfilm',\n",
    "            'width': 64,\n",
    "            'height': 64,\n",
    "            'rfilter': { 'type': 'gaussian' },\n",
    "            'sample_border': True\n",
    "        },\n",
    "    },\n",
    "    'wall': {\n",
    "        'type': 'obj',\n",
    "        'filename': '../scenes/meshes/rectangle.obj',\n",
    "        'to_world': T.translate([0, 0, -2]).scale(2.0),\n",
    "        'face_normals': True,\n",
    "        'bsdf': {\n",
    "            'type': 'diffuse',\n",
    "            'reflectance': { 'type': 'rgb', 'value': (0.5, 0.5, 0.5) },\n",
    "        }\n",
    "    },\n",
    "    'bunny': {\n",
    "        'type': 'ply',\n",
    "        'filename': '../scenes/meshes/bunny.ply',\n",
    "        'to_world': T.scale(6.5),\n",
    "        'bsdf': {\n",
    "            'type': 'diffuse',\n",
    "            'reflectance': { 'type': 'rgb', 'value': (0.3, 0.3, 0.75) },\n",
    "        },\n",
    "    },\n",
    "    'light': {\n",
    "        'type': 'obj',\n",
    "        'filename': '../scenes/meshes/sphere.obj',\n",
    "        'emitter': {\n",
    "            'type': 'area',\n",
    "            'radiance': {'type': 'rgb', 'value': [1e3, 1e3, 1e3]}\n",
    "        },\n",
    "        'to_world': T.translate([2.5, 2.5, 7.0]).scale(0.25)\n",
    "    }\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference image\n",
    "\n",
    "Next we generate the target rendering. We will later modify the bunny's position and rotation to set the initial optimization state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_ref = mi.render(scene, seed=0, spp=1024)\n",
    "\n",
    "mi.util.convert_to_bitmap(img_ref)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and latent variables\n",
    "\n",
    "As done in previous tutorial, we access the scene parameters using the `traverse()` mechanism. We then store a copy of the initial vertex positions. Those will be used later to compute the new vertex positions at every iteration, always applying a different transformation on the same base shape. \n",
    "\n",
    "Since the vertex positions in `Mesh` are stored in a linear buffer (e.g., `x_1, y_1, z_1, x_2, y_2, z_2, ...`), we use the `dr.unravel()` routine to unflatten that array into a `Point3f` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = mi.traverse(scene)\n",
    "initial_vertex_positions = dr.unravel(mi.Point3f, params['bunny.vertex_positions'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it would be possible to optimize the vertex positions of the bunny independently, in this example we are only going to optimize a translation and rotation parameter. This drastically constrains the optimization process, which helps with convergence.\n",
    "\n",
    "Therefore, we instantiate an optimizer and assign two variables to it: `angle` and `trans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mi.ad.Adam(lr=0.025)\n",
    "opt['angle'] = mi.Float(0.25)\n",
    "opt['trans'] = mi.Point2f(0.1, -0.25)\n",
    "testTensor = torch.rand((1, 199), device='cuda')\n",
    "opt['test'] = mi.TensorXf(testTensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the optimizer's point of view, those variables are the same as any other variables optimized in the previous tutorials, to the exception that when calling `opt.update()`, the optimizer doesn't know how to propagate their new values to the scene parameters. This has to be done *manually*, and we encapsulate exactly that logic in the function defined below. More detailed explaination on this can be found [here][1].\n",
    "\n",
    "After clamping the optimized variables to a proper range, this function creates a transformation object combining a translation and rotation and applies it to the vertex positions stored previously. It then flattens those new vertex positions before assigning them to the scene parameters.\n",
    "\n",
    "[1]: https://mitsuba.readthedocs.io/en/latest/src/how_to_guides/use_optimizers.html#Optimizing-latent-variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def apply_transformation(params, opt):\n",
    "    opt['trans'] = dr.clamp(opt['trans'], -0.5, 0.5)\n",
    "    opt['angle'] = dr.clamp(opt['angle'], -0.5, 0.5)\n",
    "    \n",
    "    m_tensor = np.array(opt['test'])\n",
    "    m_tensor = torch.from_numpy(m_tensor)\n",
    "\n",
    "    print(m_tensor)\n",
    "    print(m_tensor.shape)\n",
    "    \n",
    "    trafo = mi.Transform4f.translate([opt['trans'].x, opt['trans'].y, 0.0]).rotate([0, 1, 0], opt['angle'] * 100.0)\n",
    "    \n",
    "    params['bunny.vertex_positions'] = dr.ravel(trafo @ initial_vertex_positions)\n",
    "    params.update()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to apply our first transformation to get the bunny to its initial state before starting the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_transformation(params, opt)\n",
    "\n",
    "img_init = mi.render(scene, seed=0, spp=1024)\n",
    "\n",
    "mi.util.convert_to_bitmap(img_init)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we define the hyper parameters controlling the optimization, such as the number of iterations and number of samples per pixels for the differentiable rendering simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_count = 50\n",
    "spp = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IGNORE THIS: When running under pytest, adjust parameters to reduce computation time\n",
    "import os\n",
    "if 'PYTEST_CURRENT_TEST' in os.environ:\n",
    "    iteration_count = 2\n",
    "    spp = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization loop below is very similar to the one used in the other tutorials, except that we need to apply the transformation to update the bunny's state and record the relation between the rendered image and the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "for it in range(iteration_count):\n",
    "    # Apply the mesh transformation\n",
    "    apply_transformation(params, opt)\n",
    "    \n",
    "    # Perform a differentiable rendering\n",
    "    img = mi.render(scene, params, seed=it, spp=spp)\n",
    "\n",
    "    # Evaluate the objective function\n",
    "    loss = dr.sum(dr.sqr(img - img_ref)) / len(img)\n",
    "    \n",
    "    # Backpropagate through the rendering process\n",
    "    dr.backward(loss)\n",
    "\n",
    "    # Optimizer: take a gradient descent step\n",
    "    opt.step()\n",
    "\n",
    "    loss_hist.append(loss)\n",
    "    print(f\"Iteration {it:02d}: error={loss[0]:6f}, angle={opt['angle'][0]:.4f}, trans=[{opt['trans'].x[0]:.4f}, {opt['trans'].y[0]:.4f}]\", end='\\r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results\n",
    "\n",
    "Finally, let's visualize the results and plot the loss over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx-thumbnail": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "axs[0][0].plot(loss_hist)\n",
    "axs[0][0].set_xlabel('iteration'); \n",
    "axs[0][0].set_ylabel('Loss'); \n",
    "axs[0][0].set_title('Parameter error plot');\n",
    "\n",
    "axs[0][1].imshow(mi.util.convert_to_bitmap(img_init))\n",
    "axs[0][1].axis('off')\n",
    "axs[0][1].set_title('Initial Image')\n",
    "\n",
    "axs[1][0].imshow(mi.util.convert_to_bitmap(mi.render(scene, spp=1024)))\n",
    "axs[1][0].axis('off')\n",
    "axs[1][0].set_title('Optimized image')\n",
    "\n",
    "axs[1][1].imshow(mi.util.convert_to_bitmap(img_ref))\n",
    "axs[1][1].axis('off')\n",
    "axs[1][1].set_title('Reference Image');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Detailed look at Optimizer](https://mitsuba.readthedocs.io/en/latest/src/how_to_guides/use_optimizers.html)\n",
    "- [<code>mitsuba.ad.Optimizer</code>](https://mitsuba.readthedocs.io/en/latest/src/api_reference.html#mitsuba.ad.Optimizer)\n",
    "- [<code>prb_reparam</code> plugin](https://mitsuba.readthedocs.io/en/latest/src/generated/plugins_integrators.html#reparameterized-path-replay-backpropagation-integrator-prb-reparam)\n",
    "- [<code>direct_reparam</code> plugin](https://mitsuba.readthedocs.io/en/latest/src/generated/plugins_integrators.html#reparameterized-direct-integrator-direct-reparam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "524ef5c892e16adde62d9febd56e921248026795a369fc4d8cb46b781ffa4996"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
